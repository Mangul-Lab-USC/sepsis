---
title: "Prediction models to classify survivors from nonsurvivors of sepsis (raw data) using logistic regression"
author: "Thanneer Perumal"
date: '`r date()`'
output: html_document
---
  
```{r knit2synapse, eval = FALSE, include=FALSE}
## It is assumed your working directory is where this file is
library(synapseClient)
library(githubr)
library(knitr)
library(knit2synapse)

synapseLogin()

knit2synapse::storeAndKnitToFileEntity(file = 'FinalLogRegPredictionModelsRaw.Rmd',
                                       parentId = 'syn5909391',
                                       entityName = 'FinalLogRegPredictionModelsRaw.Rmd')
```

```{r libs, echo=FALSE, warning=FALSE, message=FALSE, include=FALSE, cache = FALSE}
## It is assumed your working directory is where this file is

# Clear R console screen output
cat("\014")  

# Load required libraries
library(CovariateAnalysis)
library(data.table)
library(tidyr)
library(plyr)
library(dplyr)
library(stringr)

library(RColorBrewer)
library(ggplot2)

library(parallel)
library(glmnet)
library(ranger)
library(ROCR)
library(WGCNA)

library(limma)
library(sva)
library(RankProd)
library(pracma)

library(doParallel)
library(foreach)

cl = makeCluster(2)
registerDoParallel(cl)

options(xtable.type="html")

knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  tidy = FALSE,
  cache = FALSE)
```

```{r synapseParams, include=FALSE}
parentId ="syn6175515"

ActivityName <- 'Classification analysis'

thisFileName <- 'FinalLogRegPredictionModelsRaw.Rmd'

# Github link
thisRepo <- getRepo(repository = "th1vairam/Sepsis_Metaanalysis", 
                    ref="branch", 
                    refName='classify')

thisFile <- getPermlink(repository = thisRepo,
                        repositoryPath=paste0('code/Rmd/', thisFileName))
```

```{r coallateData}
metadata.id = 'syn6039077'
all.used.id = metadata.id
metadata = read.csv(synGet(metadata.id)@filePath)
# Scale severity scores for each study
metadata = (metadata %>% ddply(.(Study), .fun = function(x){x$severity = scale(x$severity); return(x)}))
metadata$severity = as.numeric(metadata$severity)

expr.id = 'syn6039081'
all.used.id = c(all.used.id, expr.id)
expr = readRDS(synGet(expr.id)@filePath)

# Remove duplicated genes
tmp.expr = dplyr::select(expr, -Symbol)
rownames(tmp.expr) = paste('Genes', 1:dim(tmp.expr)[1], sep = '')
tmp.expr = WGCNA::collapseRows(tmp.expr, expr$Symbol, rownames(tmp.expr))$datETcollapsed
expr = tmp.expr
expr[is.na(expr)] = 0
```

```{r train, results='asis'}
# Collect training metadata and expression data
metadata.train = metadata %>%
  filter(Study %in% c('GSE40586', 'GSE10474', 'GSE13015a', 'GSE13015b', 'GSE27131', 
                      'GSE32707', 'GSE63042', 'GSE66099', 'GSE66890', 'EMTAB1548', 
                      'EMEXP3567', 'EMEXP3850'),
         !(GSM %in% c('GSM812705', 'GSM812737', 'GSM812721', 'GSM812696', 'GSM812638'))) %>% # outliers identified from own analysis
  filter(!(GSM %in% c('SL113expII', 'SL136expI', 'SL160expI', 'SL42expII', 'SS54exp2', 'SSd59exp1', 'SSd64exp2', 'SSd69exp2'))) # outliers from internal communication between Tim and Spain group
rownames(metadata.train) = metadata.train$GSM

ind = intersect(rownames(metadata.train), colnames(expr))
metadata.train = metadata.train[ind,]
expr.train = expr[,ind]
rownames(expr.train) = rownames(expr)

writeLines('Training data sets breakup')
tmp = table(droplevels(metadata.train$Study), factor(metadata.train$outcomes, levels = c('survivor', 'nonsurvivor')))
kable(tmp)
```

```{r test, results='asis'}
# Collect testing metadata and expression data
metadata.test = metadata %>%
  filter(Study %in% c('GSE54514', 'EMTAB4421', 'GSE21802', 'GSE33341', 'GSE63990', 'GSE48080', 'GSE5772', 'GSE9960'))
rownames(metadata.test) = metadata.test$GSM

ind = intersect(rownames(metadata.test), colnames(expr))
metadata.test = metadata.test[ind,]
expr.test = expr[,ind]
rownames(expr.test) = rownames(expr)

writeLines('Testing data sets breakup')
tmp = table(droplevels(metadata.test$Study), factor(metadata.test$outcomes, levels = c('survivor', 'nonsurvivor')))
kable(tmp)
```

```{r test2, results='asis'}
# Collect testing metadata and expression data (set 2 mostly private data sets)
metadata.HAI.id = 'syn7117782'
all.used.id = c(all.used.id, metadata.HAI.id)
metadata.HAI = read.csv(synGet(metadata.HAI.id)@filePath) %>%
  dplyr::rename(Study = dataset, GSM = ID, outcomes = group) %>%
  dplyr::mutate(outcomes = factor(outcomes, labels = c('survivor','nonsurvivor'))) %>%
  dplyr::select(Study, GSM, outcomes)

expr.HAI.id = 'syn7117779'
all.used.id = c(all.used.id, expr.HAI.id)
expr.HAI = readRDS(synGet(expr.HAI.id)@filePath)

metadata.VAP.id = 'syn7217802'
all.used.id = c(all.used.id, metadata.VAP.id)
metadata.VAP = read.csv(synGet(metadata.VAP.id)@filePath) %>%
  dplyr::mutate(Study = 'VAP') 
metadata.VAP = dplyr::select(metadata.VAP, Study, GSM, outcomes)

expr.VAP.id = 'syn7217800'
all.used.id = c(all.used.id, expr.VAP.id)
expr.VAP = readRDS(synGet(expr.VAP.id)@filePath)
expr.VAP = WGCNA::collapseRows(expr.VAP[,-(1)], expr.VAP$hgnc_symbol, rownames(expr.VAP))$datETcollapsed
tmp = matrix(0, 3, dim(expr.VAP)[2])
rownames(tmp) = c("EMR3","IL8","VNN3")
expr.VAP = rbind(expr.VAP, tmp)

# Merge metadata
metadata.test2 = rbindlist(list(metadata.HAI, metadata.VAP),
                           fill = T, use.names = T)

# Merge expression dataes
expr.test2 = full_join(expr.HAI %>% rownameToFirstColumn('GeneNames'),
                       expr.VAP %>% rownameToFirstColumn('GeneNames'))
rownames(expr.test2) = expr.test2$GeneNames
expr.test2$GeneNames = NULL

writeLines('Private testing data sets breakup')
tmp = table(droplevels(metadata.test2$Study), factor(metadata.test2$outcomes, levels = c('survivor', 'nonsurvivor')))
kable(tmp)
```

```{r selectGenes}
# Intersect training and testing gene sets
genes = read.table(synGet('syn6156621')@filePath, header=T) %>%
  unlist %>% as.character()

expr.train = expr.train[rownames(expr.train) %in% genes,]
expr.test = expr.test[rownames(expr.test) %in% genes,]

expr.train[is.na(expr.train)] = 0
expr.test[is.na(expr.test)] = 0
```
Performing classification with `r length(genes)` genes in the model
```{r characterise, fig.height=24, fig.width=20}
# Find principal components of expression to plot
PC <- prcomp(cbind(expr.train,expr.test), scale.=T, center = T)

# Plot PCs
plotdata <- cbind(data.frame(GSM=rownames(PC$rotation)),
                  PC$rotation[,1:9])
plotdata <- left_join(plotdata, rbind(metadata.train, metadata.test))

p <- list()

plotdata$Study = factor(plotdata$Study)
plotdata$outcomes = factor(plotdata$outcomes)

for (i in c(1,3,5,7)){
  p[[i]] <- ggplot(plotdata, aes_string(x=paste0('PC',i), y=paste0('PC',i+1)))
  p[[i]] <- p[[i]] + geom_point(aes(color=Study, shape = Study, size = outcomes))
  p[[i]] <- p[[i]] + theme_bw() + theme(legend.position="top") + scale_shape_manual(values = 1:length(levels(plotdata$Study)))
  p[[i]] <- p[[i]] + xlab(paste0('PC',i,'(',round((PC$sdev^2/sum(PC$sdev^2))[i]*100),'%)'))
  p[[i]] <- p[[i]] + ylab(paste0('PC',i+1,'(',round((PC$sdev^2/sum(PC$sdev^2))[i+1]*100),'%)'))
}

multiplot(plotlist = p[c(1,3,5,7)], cols = 2)
```

```{r combine.all.data}
# Split data 
metadata.all = metadata
rownames(metadata.all) = metadata.all$GSM
metadata.all = split(metadata.all, metadata.all$Study)
allData = lapply(metadata.all, function(mtd, expr){
  x = t(expr[,as.character(mtd$GSM)])
  y = as.numeric(factor(mtd[as.character(mtd$GSM), 'outcomes'], c('survivor', 'nonsurvivor')))
  names(y) = rownames(x)
  return(list(x = x, y = y))
}, expr)
```

### Performing logistic regression
#### Model with genomic features and study
```{r trainModel.lr.study, cache=FALSE}
# Perform logistic regression
# Get test data
x.test = t(rbind(as.numeric(as.factor(metadata.test$Study)), expr.test))
colnames(x.test)[1] = 'Study'
y.test = as.numeric(factor(metadata.test$outcomes, c('survivor', 'nonsurvivor')))
names(y.test) = metadata.test$GSM

# Add study to the input variable
allData = lapply(metadata.all, function(mtd, expr){
  x = t(rbind(mtd[as.character(mtd$GSM), 'Study'], expr[,as.character(mtd$GSM)]))
  colnames(x)[1] = 'Study'
  y = as.numeric(factor(mtd[as.character(mtd$GSM), 'outcomes'], c('survivor', 'nonsurvivor')))
  names(y) = rownames(x)
  return(list(x = x, y = y))
}, expr)
allData = allData[sapply(allData, function(x){dim(x$x)[1]}) != 0]

# Function to calculate all performance metrics
all.performance <- function(pred){
  # AUROC
  auroc = unlist(performance(pred, "auc")@y.values)
  
  # AUPR
  pre = performance(pred, "prec")@y.values[[1]]
  rec = performance(pred, "tpr")@y.values[[1]]
  ind = !(is.na(pre) | is.na(rec))
  aupr = trapz(rec[ind], pre[ind])
  
  # PPV and NPV
  ppv = performance(pred, "ppv")@y.values[[1]]
  npv = performance(pred, "npv")@y.values[[1]]
  ind = which.max(sqrt(ppv^2+npv^2))
  ppv = ppv[ind]; npv = npv[ind]
  
  return(data.frame(auroc = auroc, aupr = aupr, ppv = ppv, npv = npv))
}

# Function to calculate performance metrics for survivors and non survivors
ns.s.performance <- function(fit, y){
  pred.train = prediction(fit, y, c(1,2))
  ns = all.performance(pred.train); colnames(ns) = paste('ns',colnames(ns), sep = '.')
  
  pred.train = prediction(fit, y, c(2,1))
  s = all.performance(pred.train); colnames(s) = paste('s',colnames(s), sep = '.')
  
  return(cbind(ns, s))
}

# Function to train model
fitModel.gx.std <- function(ind, ind1, metadata.train, expr.train, x.test, y.test, allData){
  tryCatch({
    x.train = t(expr.train[ind1,ind])
    x.train = cbind(data.frame(Study = as.numeric(metadata.train[rownames(x.train),'Study'])),
                    x.train) %>%
      data.matrix()
    y.train = as.numeric(factor(metadata.train$outcomes[ind], c('survivor', 'nonsurvivor')))
    names(y.train) = metadata.train$GSM[ind]
    
    # Set penalty factor for coefficients in the model (0 for Study and 1 for all the genes)
    pf = rep(1, dim(x.train)[2])
    pf[1] = 0
    
    # Cross validation fit using penalised logistic regression
    fit.cv = cv.glmnet(x.train, y.train, family = "binomial", 
                       type.measure = 'class', parallel =TRUE,
                       penalty.factor = pf)
    coeff = as.matrix(coef.glmnet(fit.cv, s = 'lambda.min'))
    ind.var1 = rownames(coeff)
    ind.var2 = setdiff(rownames(coeff)[coeff != 0], '(Intercept)')
    
    # Prune model based on least variable of importance
    while(length(ind.var1) > length(ind.var2)){
      fit.cv1 = cv.glmnet(x.train[,ind.var2], y.train, family = "binomial",
                          type.measure = 'class', parallel =TRUE,
                          penalty.factor = pf)
      coeff = as.matrix(coef.glmnet(fit.cv1, s = 'lambda.min'))
      ind.var1 = ind.var2
      ind.var2 = setdiff(rownames(coeff)[coeff != 0], '(Intercept)')
    }
    
    # Traithning performance with the best model
    fit.train = predict.cv.glmnet(fit.cv1, newx = x.train[, ind.var2], s = "lambda.min", type = "response")
    results = cbind(data.name = 'training', ns.s.performance(fit.train, y.train))
    
    # Testing performance with the best model
    fit.test = predict.cv.glmnet(fit.cv1, newx = x.test[,ind.var2], s = "lambda.min", type = "response")
    results = rbind(results, 
                    cbind(data.name = 'testing', ns.s.performance(fit.test, y.test)))
    
    return(list(performance = results, model = fit.cv, prob = fit.test))
  }, error = function(n){
    return(list(performance = data.frame(), model = '', prob = matrix(0)))
  }) 
}

# Get trained logistic regression model results
load(synGet('syn5878027')@filePath)
all.used.id = c(all.used.id, 'syn5878027')

# Plot the performance of training and testing
tmp = ldply(baseFits.gx.std, function(x){
  x$performance
}) %>%
  dplyr::select(data.name, ns.auroc, ns.aupr, s.aupr) %>%
  gather(property, value, -data.name) %>%
  filter(data.name %in% c('training','testing')) %>%
  dplyr::mutate(data.name = factor(data.name, labels = c('training' = 'Training', 'testing' = 'Testing')),
                property = factor(property, labels = c('ns.aupr' = 'AUPR.NS', 'ns.auroc' = 'AUROC.NS', 's.aupr' = 'AUPR.S')))
p = ggplot(tmp, aes(x = data.name, y = value, color = data.name)) + geom_boxplot() + ylim(0,1)
p = p + ggtitle('Regression model with genomic features and study (80-20 split)') 
p = p + geom_abline(slope = 0, intercept = 0.5, color= "red")
p = p + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p = p + facet_grid(~.+property) + xlab('')
plotlist = list()
plotlist[[1]] = p

# Train model with all data with increasing number of features
baseFits.gx.std = foreach(i = 3:sum(baseModel.gx.std.coeff$weight > 40),
                          .packages = c('CovariateAnalysis', 'data.table',  'tidyr', 'plyr', 'dplyr', 'stringr',
                                        'glmnet', 'caret', 'ROCR', 'randomForest', 'WGCNA', 'pracma'),
                          .export = c('metadata.train', 'expr.train', 'x.test', 'y.test',
                                      'allData', 'fitModel.gx.std', 'all.performance','ns.s.performance',
                                      'baseModel.gx.std.coeff')) %dopar% {
                                        ind = 1:dim(metadata.train)[1]
                                        ind1 = which(rownames(expr.train) %in% baseModel.gx.std.coeff[1:i,1])
                                        fitModel.gx.std(ind, ind1, metadata.train, expr.train, x.test, y.test, allData)
                                      }
ind = sapply(baseFits.gx.std, function(x){class(x$model)}) == "cv.glmnet"
baseFits.gx.std = baseFits.gx.std[ind]

# Plot the performance of training and testing
tmp = ldply(baseFits.gx.std, function(x){
  x$performance
}) %>%
  dplyr::select(data.name, ns.auroc, ns.aupr, s.aupr) %>%
  gather(property, value, -data.name) %>%
  filter(data.name %in% c('training', 'testing')) %>%
  group_by(data.name, property) %>%
  dplyr::mutate(number.of.features = 1:length(baseFits.gx.std)) %>% ungroup %>%
  dplyr::mutate(data.name = factor(data.name, labels = c('training' = 'Training', 'testing' = 'Testing')),
                property = factor(property, labels = c('ns.aupr' = 'AUPR.NS', 'ns.auroc' = 'AUROC.NS', 's.aupr' = 'AUPR.S')))
p = ggplot(tmp %>% filter(property != 'rank'), aes(x = number.of.features, y = value, color = data.name)) 
p = p + geom_point() + geom_line() + ylim(0,1) + theme(legend.position = 'right')
p = p + ggtitle('Regression model with genomic features and study (Number of features)') 
p = p + geom_abline(slope = 0, intercept = 0.5, color= "red")
p = p + facet_grid(.~property)
plotlist[[2]] = p

multiplot(plotlist = plotlist, cols = 1)
n = 18;
```
`r writeLines(paste('Based on the above plot we are choosing top', n ,'features of this model. They are'))`
`r writeLines(paste(baseModel.gx.std.coeff[3:n+3,1], collapse = ','))`

```{r simulate.lr, results = 'asis'}
# Get training and testing data
ind = which(rownames(expr.train) %in% baseModel.gx.std.coeff[1:n+2,1])
x.train = t(expr.train[ind,])
x.train = cbind(data.frame(Study = as.numeric(metadata.train[rownames(x.train),'Study'])),
                x.train) %>%
  data.matrix()
y.train = as.numeric(factor(metadata.train[rownames(x.train), 'outcomes'], c('survivor', 'nonsurvivor')))
names(y.train) = metadata.train[rownames(x.train), 'GSM']
    
# Get second set of testing data (private samples)
metadata.test2 = as.data.frame(metadata.test2)
rownames(metadata.test2) = gsub('-','_',metadata.test2$GSM)

ind2 = which(rownames(expr.test2) %in% baseModel.gx.std.coeff[1:n+2,1])
x.test2 = t(expr.test2[ind2,])

x.test2 = cbind(data.frame(Study = as.numeric(metadata.test2[rownames(x.test2),'Study'])+max(as.numeric(metadata$Study))),
                x.test2) %>%
  data.matrix()
y.test2 = as.numeric(factor(metadata.test2[rownames(x.test2), 'outcomes'], c('survivor', 'nonsurvivor')))
names(y.test2) = rownames(metadata.test2)

# Set penalty factor for coefficients in the model (0 for Study and 1 for all the genes)
pf = rep(1, dim(x.train)[2])
pf[1] = 0
    
# Cross validation fit using penalised logistic regression
fit.cv = cv.glmnet(x.train, y.train, family = "binomial", 
                   type.measure = 'class', parallel =TRUE,
                   penalty.factor = pf)
coeff = as.matrix(coef.glmnet(fit.cv, s = 'lambda.min'))

# Training performance with the best model
fit.train = predict.cv.glmnet(fit.cv, newx = x.train, s = "lambda.min", type = "response")
results = cbind(data.name = 'training', ns.s.performance(fit.train, y.train))
    
# Testing performance with the best model
fit.test = predict.cv.glmnet(fit.cv, newx = x.test[,colnames(x.train)], s = "lambda.min", type = "response")
results = rbind(results, cbind(data.name = 'testing', ns.s.performance(fit.test, y.test)))

# Testing performance (private data) with the best model
fit.test2 = predict.cv.glmnet(fit.cv, newx = x.test2[,colnames(x.train)], s = "lambda.min", type = "response")
results = rbind(results, cbind(data.name = 'testing2', ns.s.performance(fit.test2, y.test2[rownames(fit.test2)])))

# Get performance in individual test data
results = rbind(results,
                metadata.test %>% filter(GSM %in% rownames(x.test)) %>% droplevels %>%
                ddply(.(Study), .fun = function(x, fit.cv, x.test, x.train){
                  fit = predict.cv.glmnet(fit.cv, newx = x.test[x$GSM,colnames(x.train)], s = "lambda.min", type = "response")
                  cbind(data.name = unique(x$Study), ns.s.performance(fit, y.test[x$GSM]))
                }, fit.cv, x.test, x.train) %>%
                  dplyr::select(-Study))


results = rbind(results,
                metadata.test2 %>% 
                  ddply(.(Study), .fun = function(x, fit.cv, x.test, y.test, x.train){
                    fit = predict.cv.glmnet(fit.cv, newx = x.test[x$GSM,colnames(x.train)], s = "lambda.min", type = "response")
                    cbind(data.name = unique(x$Study), ns.s.performance(fit, y.test[x$GSM]))
                  }, fit.cv, x.test2, y.test2, x.train) %>%
                  dplyr::select(-Study))

writeLines('Performance of the models are')
kable(results)
```

### Get leave one out predictions
```{r loocv}
# Collate all data
rownames(metadata) = metadata$GSM
expr[is.na(expr)] = min(expr, na.rm=T)

ind = which(rownames(expr) %in% baseModel.gx.std.coeff[1:n+2,1])
x.all = t(expr[ind,])
x.all = cbind(data.frame(Study = as.numeric(metadata[rownames(x.all),'Study'])),
                x.all) %>%
  data.matrix()
y.all = as.numeric(factor(metadata[, 'outcomes'], c('survivor', 'nonsurvivor')))
names(y.all) = metadata[, 'GSM']
y.all = y.all[rownames(x.all)]

LOOCV = lapply(levels(droplevels(metadata.train$Study)), function(study){
  mtd = filter(metadata.train, Study != study)
  rownames(mtd) = mtd$GSM
  
  # Get training and testing data
  ind = which(rownames(expr.train) %in% baseModel.gx.std.coeff[1:n+2,1])
  x.train = t(expr.train[ind,])
  x.train = cbind(data.frame(Study = as.numeric(mtd[rownames(x.train),'Study'])),
                  x.train) %>%
    data.matrix()
  y.train = as.numeric(factor(mtd[, 'outcomes'], c('survivor', 'nonsurvivor')))
  names(y.train) = mtd[, 'GSM']
  x.train = x.train[names(y.train),]
  
  # Set penalty factor for coefficients in the model (0 for Study and 1 for all the genes)
  pf = rep(1, dim(x.train)[2])
  pf[1] = 0
    
  # Cross validation fit using penalised logistic regression
  fit.cv = cv.glmnet(x.train, y.train, family = "binomial", 
                     type.measure = 'class', parallel =TRUE,
                     penalty.factor = pf)
  coeff = as.matrix(coef.glmnet(fit.cv, s = 'lambda.min'))

  # Traithning performance with the best model
  fit.all = predict.cv.glmnet(fit.cv, newx = x.all, s = "lambda.min", type = "response") %>%
    rownameToFirstColumn('GSM') %>%
    plyr::rename(c('1' = study))
}) %>%
  join_all
```

### Write results to synapse
```{r store.synapse}
# Get scores for all samples
ind = which(rownames(expr) %in% baseModel.gx.std.coeff[1:n+2,1])
x.train = t(expr[ind,])
x.train = cbind(data.frame(Study = as.numeric(metadata[rownames(x.train),'Study'])),
                x.train) %>%
  data.matrix()
y.train = as.numeric(factor(metadata[rownames(x.train), 'outcomes'], c('survivor', 'nonsurvivor')))
names(y.train) = metadata[rownames(x.train), 'GSM']
fit = predict.cv.glmnet(fit.cv, newx = x.train, s = "lambda.min", type = "response")
colnames(fit) = 'Scores'

# Write training scores
fit %>% rownameToFirstColumn('GSM') %>%
  left_join(dplyr::select(metadata, Study, GSM, SetName)) %>%
  filter(SetName == 'Training') %>%
  dplyr::select(Study, GSM, Scores) %>%
  write.table(file = 'training_scores_lr.tsv', sep = '\t', row.names = F, quote=F)
obj = File('training_scores_lr.tsv', name = 'Training scores (logistic regression)', parentId = 'syn6175515')
obj = synStore(obj, used = all.used.id, executed = thisFile, activityName = ActivityName)

# Write validation scores
rbind(fit.test %>% rownameToFirstColumn('GSM') %>%
        left_join(dplyr::select(metadata.test, Study, GSM)) %>%
        plyr::rename(c('1' = 'Scores')) %>%
        dplyr::select(Study, GSM, Scores),
      fit.test2 %>% rownameToFirstColumn('GSM') %>%
        left_join(dplyr::select(metadata.test2, Study, GSM) %>%
                    dplyr::mutate(GSM = gsub('-','_',GSM))) %>%
        plyr::rename(c('1' = 'Scores')) %>%
        dplyr::select(Study, GSM, Scores)) %>%
  write.table(file = 'validation_scores_lr.tsv', sep = '\t', row.names = F, quote=F)
obj = File('validation_scores_lr.tsv', name = 'Validation scores (logistic regression)', parentId = 'syn6175515')
obj = synStore(obj, used = all.used.id, executed = thisFile, activityName = ActivityName)

# Write leave one out cross validation scores
LOOCV %>% write.table(file = 'loocv.lr.tsv', sep = '\t', row.names = F, quote=F)
obj = File('loocv.lr.tsv', name = 'Leave One Data Out CrossValidation Scores (logistic regression)', parentId = 'syn6175517')
obj = synStore(obj, used = all.used.id, executed = thisFile, activityName = ActivityName)

# Write features to synapse
coeff %>% rownameToFirstColumn('Feature') %>% 
  setnames(c('Feature','1'),c('Feature','Coefficients')) %>%
  write.table(file = 'features.lr.tsv', sep = '\t', row.names = F, quote=F)
obj = File('features.lr.tsv', name = 'Features (logistic regression)', parentId = 'syn6175516')
obj = synStore(obj, used = all.used.id, executed = thisFile, activityName = ActivityName)
```

### Use exisiting features to predict serverity
```{r simulate.lr.sev, results = 'asis'}
# Get training and testing data
rownames(metadata) = metadata$GSM
ind = which(rownames(expr.train) %in% baseModel.gx.std.coeff[1:n+2,1])
x.train = t(expr.train[ind,])
x.train = cbind(data.frame(Study = as.numeric(metadata[rownames(x.train),'Study'])),
                x.train) %>%
  data.matrix()
y.train = as.numeric(metadata[rownames(x.train),'severity'])
names(y.train) = rownames(x.train)
y.train = na.omit(y.train)
x.train = x.train[names(y.train),]

# Get testing data
ind = which(rownames(expr.test) %in% baseModel.gx.std.coeff[1:n+2,1])
x.test = t(expr.test[ind,])
x.test = cbind(data.frame(Study = as.numeric(metadata[rownames(x.test),'Study'])),
                x.test) %>%
  data.matrix()
y.test = as.numeric(metadata[rownames(x.test),'severity'])
names(y.test) = rownames(x.test)
y.test = na.omit(y.test)
x.test = x.test[names(y.test),]

# Set penalty factor for coefficients in the model (0 for Study and 1 for all the genes)
pf = rep(1, dim(x.train)[2])
pf[1] = 0
    
# Cross validation fit using penalised logistic regression
fit.cv = cv.glmnet(x.train, y.train, family = "gaussian", 
                   parallel =TRUE,
                   penalty.factor = pf)
coeff = as.matrix(coef.glmnet(fit.cv, s = 'lambda.min'))

# Training performance with the best model
fit.train = predict.cv.glmnet(fit.cv, newx = x.train, s = "lambda.min", type = "response")
R2.train = 1-(sum((fit.train-y.train)^2)/sum((y.train-mean(y.train))^2))

# Testing performance with the best model
fit.test = predict.cv.glmnet(fit.cv, newx = x.test[,colnames(x.train)], s = "lambda.min", type = "response")
R2.test = 1-(sum((fit.test-y.test)^2)/sum((y.test-mean(y.test))^2))

writeLines(paste('The training and testing R2 values are', round(R2.train,2), round(R2.test,2), 'respectively'))

########### Retrian models with severity scores
# Get training and testing data
ind = which(rownames(expr.train) %in% baseModel.gx.std.coeff[1:n+2,1])
x.train = t(expr.train[ind,])
x.train = cbind(data.frame(Study = as.numeric(metadata.train[rownames(x.train),'Study']),
                           Severity = as.numeric(metadata[rownames(x.train),'severity'])),
                x.train) %>%
  data.matrix()
y.train = as.numeric(factor(metadata.train[rownames(x.train), 'outcomes'], c('survivor', 'nonsurvivor')))
names(y.train) = metadata.train[rownames(x.train), 'GSM']

x.train = na.omit(x.train)
y.train = y.train[rownames(x.train)]

# Get testing data
ind = which(rownames(expr.test) %in% baseModel.gx.std.coeff[1:n+2,1])
x.test = t(expr.test[ind,])
x.test = cbind(data.frame(Study = as.numeric(metadata.test[rownames(x.test),'Study']),
                           Severity = as.numeric(metadata[rownames(x.test),'severity'])),
                x.test) %>%
  data.matrix()
y.test = as.numeric(factor(metadata.test[rownames(x.test), 'outcomes'], c('survivor', 'nonsurvivor')))
names(y.test) = metadata.test[rownames(x.test), 'GSM']

x.test = na.omit(x.test)
y.test = y.test[rownames(x.test)]

# Set penalty factor for coefficients in the model (0 for Study and 1 for all the genes)
pf = rep(1, dim(x.train)[2])
pf[1:2] = 0
    
# Cross validation fit using penalised logistic regression
fit.cv = cv.glmnet(x.train, y.train, family = "binomial", 
                   type.measure = 'class', parallel =TRUE,
                   penalty.factor = pf)
coeff = as.matrix(coef.glmnet(fit.cv, s = 'lambda.min'))

# Traithning performance with the best model
fit.train = predict.cv.glmnet(fit.cv, newx = x.train, s = "lambda.min", type = "response")
results.sev = cbind(data.name = 'training', ns.s.performance(fit.train, y.train))
    
# Testing performance with the best model
fit.test = predict.cv.glmnet(fit.cv, newx = x.test[,colnames(x.train)], s = "lambda.min", type = "response")
results.sev = rbind(results.sev, cbind(data.name = 'testing', ns.s.performance(fit.test, y.test)))

# Get performance in individual test data
results.sev = rbind(results.sev,
                    metadata.test %>% filter(GSM %in% rownames(x.test)) %>% droplevels %>%
                      ddply(.(Study), .fun = function(x, fit.cv, x.test, x.train, y.test, y.train){
                        x = filter(x, !is.na(severity))
                        fit = predict.cv.glmnet(fit.cv, newx = x.test[as.character(x$GSM),], s = "lambda.min", type = "response")
                        cbind(data.name = unique(x$Study), ns.s.performance(fit, y.test[as.character(x$GSM)]))
                        }, fit.cv, x.test, x.train, y.test, y.train) %>%
                      dplyr::select(-Study))

writeLines('Performance of the models with severity are')
kable(results.sev)

tmp = rbindlist(list(base.model = results, base.model.severity = results.sev), idcol = 'Model') 

writeLines('Comparative model performance: AUROC')
tmp %>% 
  dplyr::select(Model, data.name, ns.auroc) %>%
  spread(Model, ns.auroc) %>% 
  kable

writeLines('Comparative model performance: AUPR NS')
tmp %>% 
  dplyr::select(Model, data.name, ns.aupr) %>%
  spread(Model, ns.aupr) %>% 
  kable

writeLines('Comparative model performance: AUPR S')
tmp %>% 
  dplyr::select(Model, data.name, s.aupr) %>%
  spread(Model, s.aupr) %>% 
  kable
```